{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c14f8e4",
   "metadata": {},
   "source": [
    "# Stock fetching, Cleaning, and Storage\n",
    "#### This notebook is going to:\n",
    "\n",
    "###### Fetch 3 non consecutive 2 month slices of Stock data for 2 companies from the year 2024, this example will use APPLE and Amazon\n",
    "###### Each of these months will be proccessed differently\n",
    "###### The first month will be written directly to a SQL table\n",
    "###### The second month will be written to a JSON file\n",
    "###### The third month will be written to a CSV file\n",
    "\n",
    "###### We will then load and randomly scramble each of the APPLE files before appending them the SQL table\n",
    "\n",
    "###### Finally we are going to build a dataframe from the SQL table, determine the missing months, make the appropriate API calls to retrieve the missing months, complete the data frame and update the SQL table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c780e",
   "metadata": {},
   "source": [
    "### Imports & Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ac7a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Scripts directory not found at /home/eowre/Documents/DataEngineering/scripts",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m scripts_dir = project_root / \u001b[33m\"\u001b[39m\u001b[33mscripts\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scripts_dir.exists():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScripts directory not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscripts_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mScripts directory contents:\u001b[39m\u001b[33m\"\u001b[39m, os.listdir(scripts_dir))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Import handlers\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Scripts directory not found at /home/eowre/Documents/DataEngineering/scripts"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Dynamically determine the project root directory based on the current working directory\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parents[1]  # Adjust to go up one level from the notebooks directory\n",
    "sys.path.append(str(current_dir))\n",
    "\n",
    "# Verify the scripts directory exists\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "if not scripts_dir.exists():\n",
    "    raise FileNotFoundError(f\"Scripts directory not found at {scripts_dir}\")\n",
    "\n",
    "print(\"Scripts directory contents:\", os.listdir(scripts_dir))\n",
    "\n",
    "# Import handlers\n",
    "from scripts.handlers.stockHandler import AVStockDataHandler\n",
    "from scripts.handlers.storageHandler import storageHandler\n",
    "from scripts.handlers.helperHandler import helperHandler\n",
    "from scripts.handlers.scrambleHandler import scrambleHandler\n",
    "from scripts.handlers.SQLHandler import SQLHandler\n",
    "from scripts.handlers.cleaningHandler import cleaningHandler\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / \"config.env\")\n",
    "\n",
    "# Retrieve the API key and DB_PATH from the environment variables\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "DB_PATH = os.getenv(\"DB_PATH\")\n",
    "\n",
    "# Raise an error if the API key or DB_PATH is not found\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found. Please set the ALPHA_VANTAGE_API_KEY in config.env.\")\n",
    "\n",
    "if not DB_PATH:\n",
    "    raise ValueError(\"Database path not found. Please set the DB_PATH in config.env.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2997838",
   "metadata": {},
   "source": [
    "### Handlers, Tickers, And Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the handlers\n",
    "stock_handler = AVStockDataHandler(API_KEY)\n",
    "storage_handler = storageHandler()\n",
    "SQL_handler = SQLHandler(DB_PATH)\n",
    "scramble_handler = scrambleHandler()\n",
    "helper_handler = helperHandler()\n",
    "cleaning_handler = cleaningHandler()\n",
    "\n",
    "# Tickers to fetch data for\n",
    "tickers = ['AAPL', 'AMZN']\n",
    "\n",
    "# Date range for fetching data\n",
    "start_date_1 = '2024-01-01'\n",
    "start_date_2 = '2024-05-01'\n",
    "start_date_3 = '2024-09-01'\n",
    "end_date_1 = '2024-02-29'\n",
    "end_date_2 = '2024-06-30'\n",
    "end_date_3 = '2024-10-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a031e",
   "metadata": {},
   "source": [
    "### Fetching and Storing ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a671aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch the data, \n",
    "SQL_data_slice_1 = stock_handler.fetch_multiple_tickers(tickers, start_date_1, end_date_1)\n",
    "csv_data_slice_2 = stock_handler.fetch_multiple_tickers(tickers, start_date_2, end_date_2)\n",
    "json_data_slice_3 = stock_handler.fetch_multiple_tickers(tickers, start_date_3, end_date_3)\n",
    "\n",
    "SQL_handler.save_dfs_to_table(SQL_data_slice_1)\n",
    "storage_handler.multiple_dfs_to_csv_and_json(csv_data_slice_2, file_type='csv')\n",
    "storage_handler.multiple_dfs_to_csv_and_json(json_data_slice_3, file_type='json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e4040",
   "metadata": {},
   "source": [
    "### File Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex patterns for locating AAPL csv and json files\n",
    "AAPL_pattern = r\".*AAPL.*\"  # Matches any CSV file starting with \"AAPL\"\n",
    "\n",
    "# Use the helper handler to locate files matching the patterns\n",
    "aapl_files = helper_handler.find_files(\"raw_data\", AAPL_pattern)\n",
    "\n",
    "# Build dataframes from the located files\n",
    "aapl_dfs = []\n",
    "for file in aapl_files:\n",
    "    df = storage_handler.df_builder(file)\n",
    "    aapl_dfs.append(df)\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "aapl_df = pd.concat(aapl_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc407ca0",
   "metadata": {},
   "source": [
    "### Scrambling data\n",
    "\n",
    "###### NOTE: This scramble method can return a new object but the operations are performed in place on the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the concatenated dataframe\n",
    "print(aapl_df)\n",
    "\n",
    "# Scramble the data\n",
    "scramble_handler.scramble_df(aapl_df)\n",
    "\n",
    "# Print the scrambled dataframe\n",
    "print(aapl_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
